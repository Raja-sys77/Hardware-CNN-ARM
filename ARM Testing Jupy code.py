import cv2
import numpy as np
import time
import threading
from pynq import Overlay, allocate
import IPython.display

# ==========================================
# 1. HARDWARE (PL)
# ==========================================
print("âš¡ Loading Bitstream...")
ol = Overlay("design_1.bit")
dma = ol.axi_dma_0
accel = ol.cnn_accelerator_0

# Configure IP
H_IP, W_IP = 192, 192
accel.register_map.rows = H_IP
accel.register_map.cols = W_IP
accel.register_map.CTRL.AP_START = 1
accel.register_map.CTRL.AUTO_RESTART = 1
weights_buf = allocate(shape=(50,), dtype=np.int32)
accel.register_map.Memory_weights = weights_buf.device_address

# DMA Buffers
input_buffer = allocate(shape=(H_IP, W_IP, 4), dtype=np.uint8)
output_buffer = allocate(shape=(H_IP, W_IP, 4), dtype=np.uint8)

print("âœ… FPGA Ready.")

# ==========================================
# 2. AI MODEL (CPU)
# ==========================================
print("ðŸ§  Loading MobileNet-SSD...")
net = cv2.dnn.readNetFromCaffe("MobileNetSSD_deploy.prototxt", "MobileNetSSD_deploy.caffemodel")
CLASSES = ["background", "aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car", "cat", "chair", "cow", "diningtable", "dog", "horse", "motorbike", "person", "pottedplant", "sheep", "sofa", "train", "tvmonitor"]

# ==========================================
# 3. SHARED DATA
# ==========================================
frame_shared = None
detections_shared = None
pl_metric_shared = 0
ai_fps = 0.0
pl_fps = 0.0
lock = threading.Lock()
running = True

# ==========================================
# 4. WORKER THREADS
# ==========================================

# --- THREAD A: AI (CPU) ---
def ai_worker():
Â  Â  global frame_shared, detections_shared, ai_fps, running
Â  Â  while running:
Â  Â  Â  Â  with lock:
Â  Â  Â  Â  Â  Â  if frame_shared is None:Â 
Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(0.01); continue
Â  Â  Â  Â  Â  Â  local_frame = frame_shared.copy()
Â  Â  Â  Â Â 
Â  Â  Â  Â  t_start = time.time()
Â  Â  Â  Â  # Resize to 300x300 for Model
Â  Â  Â  Â  blob = cv2.dnn.blobFromImage(cv2.resize(local_frame, (300, 300)), 0.007843, (300, 300), 127.5)
Â  Â  Â  Â  net.setInput(blob)
Â  Â  Â  Â  out = net.forward()
Â  Â  Â  Â  t_end = time.time()
Â  Â  Â  Â Â 
Â  Â  Â  Â  with lock:
Â  Â  Â  Â  Â  Â  detections_shared = out
Â  Â  Â  Â  Â  Â  ai_fps = 1.0 / (t_end - t_start)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Sleep to let Video thread run
Â  Â  Â  Â  time.sleep(0.1)

# --- THREAD B: FPGA (PL) ---
def pl_worker():
Â  Â  global frame_shared, pl_metric_shared, pl_fps, running
Â  Â  while running:
Â  Â  Â  Â  with lock:
Â  Â  Â  Â  Â  Â  if frame_shared is None:Â 
Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(0.01); continue
Â  Â  Â  Â  Â  Â  local_frame = frame_shared.copy()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  t_start = time.time()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Hardware Process
Â  Â  Â  Â  small = cv2.resize(local_frame, (W_IP, H_IP), interpolation=cv2.INTER_NEAREST)
Â  Â  Â  Â  frame_rgba = cv2.cvtColor(small, cv2.COLOR_BGR2BGRA)
Â  Â  Â  Â Â 
Â  Â  Â  Â  input_buffer[:] = frame_rgba
Â  Â  Â  Â  dma.sendchannel.transfer(input_buffer)
Â  Â  Â  Â  dma.recvchannel.transfer(output_buffer)
Â  Â  Â  Â  dma.sendchannel.wait()
Â  Â  Â  Â  dma.recvchannel.wait()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Read Result
Â  Â  Â  Â  result = output_buffer.copy()
Â  Â  Â  Â  t_end = time.time()
Â  Â  Â  Â Â 
Â  Â  Â  Â  with lock:
Â  Â  Â  Â  Â  Â  pl_fps = 1.0 / (t_end - t_start)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # CRITICAL FIX: Sleep to cap PL at ~30 FPS
Â  Â  Â  Â  # This prevents PL from eating all CPU bandwidth
Â  Â  Â  Â  time.sleep(0.03)

# Start Threads
t1 = threading.Thread(target=ai_worker)
t2 = threading.Thread(target=pl_worker)
t1.start()
t2.start()
print("âœ… Threads Started (Balanced Mode).")

# ==========================================
# 5. MAIN VIDEO LOOP (Optimized Display)
# ==========================================
# Use 320x240 for Capture if 640x360 is too slow on your network
gst_str = "v4l2src device=/dev/video0 ! image/jpeg, width=640, height=360, framerate=30/1 ! jpegdec ! videoconvert ! appsink drop=1"
cap = cv2.VideoCapture(gst_str, cv2.CAP_GSTREAMER)

if not cap.isOpened():
Â  Â  print("âŒ Camera Fail.")
Â  Â  running = False
Â  Â  t1.join(); t2.join()
else:
Â  Â  print("ðŸš€ STARTING OPTIMIZED DEMO...")
Â  Â  try:
Â  Â  Â  Â  frame_count = 0
Â  Â  Â  Â  display_counter = 0
Â  Â  Â  Â  start_time = time.time()
Â  Â  Â  Â  video_fps = 0
Â  Â  Â  Â Â 
Â  Â  Â  Â  while True:
Â  Â  Â  Â  Â  Â  # 1. Capture (As fast as possible)
Â  Â  Â  Â  Â  Â  ret, frame = cap.read()
Â  Â  Â  Â  Â  Â  if not ret: break
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Update Shared Frame
Â  Â  Â  Â  Â  Â  with lock:
Â  Â  Â  Â  Â  Â  Â  Â  frame_shared = frame.copy()
Â  Â  Â  Â  Â  Â  Â  Â  dets = detections_shared
Â  Â  Â  Â  Â  Â  Â  Â  val_ai_fps = ai_fps
Â  Â  Â  Â  Â  Â  Â  Â  val_pl_fps = pl_fps
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Calculate Capture FPS (The True Speed)
Â  Â  Â  Â  Â  Â  frame_count += 1
Â  Â  Â  Â  Â  Â  if time.time() - start_time > 1:
Â  Â  Â  Â  Â  Â  Â  Â  video_fps = frame_count / (time.time() - start_time)
Â  Â  Â  Â  Â  Â  Â  Â  frame_count = 0
Â  Â  Â  Â  Â  Â  Â  Â  start_time = time.time()

Â  Â  Â  Â  Â  Â  # 2. Display Strategy: Only show every 2nd or 3rd frame
Â  Â  Â  Â  Â  Â  # This allows the loop to run faster than the browser can render
Â  Â  Â  Â  Â  Â  display_counter += 1
Â  Â  Â  Â  Â  Â  if display_counter % 2 == 0:Â 
Â  Â  Â  Â  Â  Â  Â  Â  display = frame.copy()
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # Draw Boxes
Â  Â  Â  Â  Â  Â  Â  Â  if dets is not None:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (h, w) = display.shape[:2]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for i in range(dets.shape[2]):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  confidence = dets[0, 0, i, 2]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if confidence > 0.4:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  idx = int(dets[0, 0, i, 1])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  box = dets[0, 0, i, 3:7] * np.array([w, h, w, h])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (startX, startY, endX, endY) = box.astype("int")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cv2.rectangle(display, (startX, startY), (endX, endY), (0, 255, 0), 2)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label = f"{CLASSES[idx]}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cv2.putText(display, label, (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

Â  Â  Â  Â  Â  Â  Â  Â  # Stats
Â  Â  Â  Â  Â  Â  Â  Â  cv2.putText(display, f"Video: {int(video_fps)} FPS", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
Â  Â  Â  Â  Â  Â  Â  Â  cv2.putText(display, f"AI: {val_ai_fps:.1f} FPS", (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
Â  Â  Â  Â  Â  Â  Â  Â  cv2.putText(display, f"PL: {val_pl_fps:.1f} FPS", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 100, 0), 2)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # Send to Browser
Â  Â  Â  Â  Â  Â  Â  Â  _, fmt = cv2.imencode('.jpg', display)
Â  Â  Â  Â  Â  Â  Â  Â  IPython.display.display(IPython.display.Image(data=fmt))
Â  Â  Â  Â  Â  Â  Â  Â  IPython.display.clear_output(wait=True)
Â  Â  Â  Â  Â  Â Â 
Â  Â  except KeyboardInterrupt:
Â  Â  Â  Â  print("ðŸ›‘ Stopped.")
Â  Â  finally:
Â  Â  Â  Â  running = False
Â  Â  Â  Â  t1.join(); t2.join()
Â  Â  Â  Â  cap.release()
Â  Â  Â  Â  input_buffer.freebuffer(); output_buffer.freebuffer(); weights_buf.freebuffer()
